{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation, Add,Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import layers, models, callbacks\n\n\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n\nimport numpy as np\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os, shutil, pathlib\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport glob\nfrom sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-06-13T11:49:46.634239Z","iopub.execute_input":"2023-06-13T11:49:46.634617Z","iopub.status.idle":"2023-06-13T11:49:50.428046Z","shell.execute_reply.started":"2023-06-13T11:49:46.634585Z","shell.execute_reply":"2023-06-13T11:49:50.427040Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing required libraries\nimport os\nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd \n\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.autonotebook import tqdm\n\nimport tensorflow as tf\nfrom keras import Sequential\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam, SGD\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\nfrom keras.layers import Lambda, Input, GlobalAveragePooling2D,BatchNormalization\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import load_img","metadata":{"execution":{"iopub.status.busy":"2023-06-13T11:49:50.430133Z","iopub.execute_input":"2023-06-13T11:49:50.430918Z","iopub.status.idle":"2023-06-13T11:49:50.442050Z","shell.execute_reply.started":"2023-06-13T11:49:50.430849Z","shell.execute_reply":"2023-06-13T11:49:50.440934Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_1974/1260587626.py:10: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm\n","output_type":"stream"}]},{"cell_type":"code","source":"labels = pd.read_csv('/kaggle/input/c/dog-breed-identification/labels.csv')\nlabels.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-13T11:49:50.948178Z","iopub.execute_input":"2023-06-13T11:49:50.948531Z","iopub.status.idle":"2023-06-13T11:49:50.983209Z","shell.execute_reply.started":"2023-06-13T11:49:50.948502Z","shell.execute_reply":"2023-06-13T11:49:50.982296Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                 id             breed\n0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n2  001cdf01b096e06d78e9e5112d419397          pekinese\n3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>breed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n      <td>boston_bull</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n      <td>dingo</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>001cdf01b096e06d78e9e5112d419397</td>\n      <td>pekinese</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n      <td>bluetick</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n      <td>golden_retriever</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#.....................................\n#Create list of alphabetically sorted labels.\nclasses = sorted(list(set(labels['breed'])))\nn_classes = len(classes)\nprint('Total unique breed {}'.format(n_classes))\n\n\n#Map each label string to an integer label.\nclass_to_num = dict(zip(classes, range(n_classes)))","metadata":{"execution":{"iopub.status.busy":"2023-06-13T11:49:52.513022Z","iopub.execute_input":"2023-06-13T11:49:52.513408Z","iopub.status.idle":"2023-06-13T11:49:52.523075Z","shell.execute_reply.started":"2023-06-13T11:49:52.513380Z","shell.execute_reply":"2023-06-13T11:49:52.521706Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Total unique breed 120\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = pd.read_csv('/kaggle/input/dog-breed-identification/labels.csv')\nlabels.head()\n\n\n#.....................................\n#Create list of alphabetically sorted labels.\nclasses = sorted(list(set(labels['breed'])))\nn_classes = len(classes)\nprint('Total unique breed {}'.format(n_classes))\n\n\n#Map each label string to an integer label.\nclass_to_num = dict(zip(classes, range(n_classes)))\n\n\n\n#............................................\ninput_shape = (331,331,3)\n\ndef images_to_array(directory, label_dataframe, target_size = input_shape):\n    \n    image_labels = label_dataframe['breed']\n    images = np.zeros([len(label_dataframe), target_size[0], target_size[1], target_size[2]],dtype=np.uint8) #as we have huge data and limited ram memory. uint8 takes less memory\n    y = np.zeros([len(label_dataframe),1],dtype = np.uint8)\n    \n    for ix, image_name in enumerate(tqdm(label_dataframe['id'].values)):\n        img_dir = os.path.join(directory, image_name + '.jpg')\n        img = load_img(img_dir, target_size = target_size)\n        images[ix] = img\n        del img\n        \n        dog_breed = image_labels[ix]\n        y[ix] = class_to_num[dog_breed]\n    \n    y = to_categorical(y)\n    \n    return images, y\n\n\n\n#..............................\nimport time \nt = time.time()\n\nX, y = images_to_array('/kaggle/input/dog-breed-identification/train', labels[:])\n\nprint('runtime in seconds: {}'.format(time.time() - t))\n\n\n\n\n#............................................\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42)\n\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)\n\n\n\n#..................................\n#Learning Rate Annealer\nlrr= ReduceLROnPlateau(monitor='val_acc', factor=.01, patience=3, min_lr=1e-5,verbose = 1)\n\n#Prepare call backs\nEarlyStop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n\n\n\n\n\n#....................................\n# Hyperparameters\nbatch_size= 128\nepochs=25\nlearn_rate=.001\nsgd=SGD(learning_rate=learn_rate, momentum=0.9, nesterov=False)\nadam=Adam(learning_rate=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None,  amsgrad=False)\n\n\n\n\n\n\n\n\n#..........................\n#function to extract features from the dataset by a given pretrained model\nimg_size = (331,331,3)\n\ndef get_features(model_name, model_preprocessor, input_size, data):\n\n    input_layer = Input(input_size)\n    preprocessor = Lambda(model_preprocessor)(input_layer)\n    base_model = model_name(weights='imagenet', include_top=False,\n                            input_shape=input_size)(preprocessor)\n    avg = GlobalAveragePooling2D()(base_model)\n    feature_extractor = Model(inputs = input_layer, outputs = avg)\n    \n    #Extract feature.\n    feature_maps = feature_extractor.predict(data, verbose=1)\n    print('Feature maps shape: ', feature_maps.shape)\n    return feature_maps\n\n\n\n#...............................\n# Extract features using InceptionV3 \nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\ninception_preprocessor = preprocess_input\ninception_features = get_features(InceptionV3,\n                                  inception_preprocessor,\n                                  img_size, X_train)\n\nprint('Inception feature maps shape', inception_features.shape)\n\n\n\n\n\n\n#...................\ndel X, X_train #to free up some ram memory\ngc.collect()\n\n\n\n\n\n\n\n\n#.........................\n#Prepare Deep net\n\nmodel = Sequential()\n# model.add(Dense(1028,input_shape=(final_features.shape[1],)))\nmodel.add(Dropout(0.7,input_shape=(inception_features.shape[1],)))\nmodel.add(Dense(n_classes,activation= 'softmax'))\n\nmodel.compile(optimizer=adam,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n\n\n#......................\n#Training the model. \nhistory = model.fit(inception_features, y_train,\n            batch_size=batch_size,\n            epochs=epochs,\n            validation_split=0.2,\n            callbacks=[lrr, EarlyStop])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Extract test data features.\ndef extact_features(data):\n    inception_features = get_features(InceptionV3, inception_preprocessor, img_size, data)\n    print('Inception feature maps shape', inception_features.shape)\n    return inception_features\n\ntest_features = extact_features(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(test_features)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nmodel.save(\"model.h5\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.argmax(y_pred,axis=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ny_test_indices = np.argmax(y_test, axis=1)\ny_pred_indices = np.argmax(y_pred, axis=1)\n\naccuracy_score(y_test_indices, y_pred_indices)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test on 1 image","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = pd.read_csv('/kaggle/input/c/dog-breed-identification/labels.csv')\n# labels = labels.head(1)\nlabels","metadata":{"execution":{"iopub.status.busy":"2023-06-13T12:24:56.769912Z","iopub.execute_input":"2023-06-13T12:24:56.770300Z","iopub.status.idle":"2023-06-13T12:24:56.805973Z","shell.execute_reply.started":"2023-06-13T12:24:56.770270Z","shell.execute_reply":"2023-06-13T12:24:56.804939Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"                                     id                     breed\n0      000bec180eb18c7604dcecc8fe0dba07               boston_bull\n1      001513dfcb2ffafc82cccf4d8bbaba97                     dingo\n2      001cdf01b096e06d78e9e5112d419397                  pekinese\n3      00214f311d5d2247d5dfe4fe24b2303d                  bluetick\n4      0021f9ceb3235effd7fcde7f7538ed62          golden_retriever\n...                                 ...                       ...\n10217  ffd25009d635cfd16e793503ac5edef0                    borzoi\n10218  ffd3f636f7f379c51ba3648a9ff8254f            dandie_dinmont\n10219  ffe2ca6c940cddfee68fa3cc6c63213f                  airedale\n10220  ffe5f6d8e2bff356e9482a80a6e29aac        miniature_pinscher\n10221  fff43b07992508bc822f33d8ffd902ae  chesapeake_bay_retriever\n\n[10222 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>breed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n      <td>boston_bull</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n      <td>dingo</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>001cdf01b096e06d78e9e5112d419397</td>\n      <td>pekinese</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n      <td>bluetick</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n      <td>golden_retriever</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10217</th>\n      <td>ffd25009d635cfd16e793503ac5edef0</td>\n      <td>borzoi</td>\n    </tr>\n    <tr>\n      <th>10218</th>\n      <td>ffd3f636f7f379c51ba3648a9ff8254f</td>\n      <td>dandie_dinmont</td>\n    </tr>\n    <tr>\n      <th>10219</th>\n      <td>ffe2ca6c940cddfee68fa3cc6c63213f</td>\n      <td>airedale</td>\n    </tr>\n    <tr>\n      <th>10220</th>\n      <td>ffe5f6d8e2bff356e9482a80a6e29aac</td>\n      <td>miniature_pinscher</td>\n    </tr>\n    <tr>\n      <th>10221</th>\n      <td>fff43b07992508bc822f33d8ffd902ae</td>\n      <td>chesapeake_bay_retriever</td>\n    </tr>\n  </tbody>\n</table>\n<p>10222 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create list of alphabetically sorted labels.\nclasses = sorted(list(set(labels['breed'])))\nn_classes = len(classes)\nprint('Total unique breed {}'.format(n_classes))\n\n\n#Map each label string to an integer label.\nclass_to_num = dict(zip(classes, range(n_classes)))","metadata":{"execution":{"iopub.status.busy":"2023-06-13T12:24:59.429006Z","iopub.execute_input":"2023-06-13T12:24:59.429397Z","iopub.status.idle":"2023-06-13T12:24:59.437104Z","shell.execute_reply.started":"2023-06-13T12:24:59.429368Z","shell.execute_reply":"2023-06-13T12:24:59.436002Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Total unique breed 120\n","output_type":"stream"}]},{"cell_type":"code","source":"# class_to_num","metadata":{"execution":{"iopub.status.busy":"2023-06-21T05:38:17.561134Z","iopub.execute_input":"2023-06-21T05:38:17.561396Z","iopub.status.idle":"2023-06-21T05:38:17.567726Z","shell.execute_reply.started":"2023-06-21T05:38:17.561372Z","shell.execute_reply":"2023-06-21T05:38:17.566108Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"for i in class_to_num:\n    if class_to_num[i]==49:\n        print(i)\n     \n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-13T12:36:29.349201Z","iopub.execute_input":"2023-06-13T12:36:29.349578Z","iopub.status.idle":"2023-06-13T12:36:29.356098Z","shell.execute_reply.started":"2023-06-13T12:36:29.349547Z","shell.execute_reply":"2023-06-13T12:36:29.355017Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"golden_retriever\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_labels = labels[:]['breed']\nimage_labels","metadata":{"execution":{"iopub.status.busy":"2023-06-13T11:55:35.882987Z","iopub.execute_input":"2023-06-13T11:55:35.883349Z","iopub.status.idle":"2023-06-13T11:55:35.890934Z","shell.execute_reply.started":"2023-06-13T11:55:35.883320Z","shell.execute_reply":"2023-06-13T11:55:35.890045Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"0    boston_bull\nName: breed, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"input_shape = (331,331,3)\ntarget_size = input_shape\nimages = np.zeros([len(labels[:]), target_size[0], target_size[1], target_size[2]],dtype=np.uint8) #as we have huge data and limited ram memory. uint8 takes less memory\n","metadata":{"execution":{"iopub.status.busy":"2023-06-13T11:55:37.614321Z","iopub.execute_input":"2023-06-13T11:55:37.615141Z","iopub.status.idle":"2023-06-13T11:55:37.621665Z","shell.execute_reply.started":"2023-06-13T11:55:37.615102Z","shell.execute_reply":"2023-06-13T11:55:37.620347Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" y = np.zeros([len(labels[:]),1],dtype = np.uint8)\n    \nfor ix, image_name in enumerate(tqdm(labels[:]['id'].values)):\n        img_dir = os.path.join('/kaggle/input/dog-test-2', image_name + '.jpg')\n        print(img_dir)\n        img = load_img(img_dir, target_size = target_size)\n        images[ix] = img\n        del img\n        \n#         dog_breed = labels[:][ix]\n#         y[ix] = class_to_num[dog_breed]\n    \n# y = to_categorical(y)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T11:55:59.949313Z","iopub.execute_input":"2023-06-13T11:55:59.949673Z","iopub.status.idle":"2023-06-13T11:55:59.984800Z","shell.execute_reply.started":"2023-06-13T11:55:59.949645Z","shell.execute_reply":"2023-06-13T11:55:59.983850Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c580a8d57664058b4445233d317051e"}},"metadata":{}},{"name":"stdout","text":"/kaggle/input/dog-test-2/000bec180eb18c7604dcecc8fe0dba07.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_features(model_name, model_preprocessor, input_size, data):\n\n    input_layer = Input(input_size)\n    preprocessor = Lambda(model_preprocessor)(input_layer)\n    base_model = model_name(weights='imagenet', include_top=False,\n                            input_shape=input_size)(preprocessor)\n    avg = GlobalAveragePooling2D()(base_model)\n    feature_extractor = Model(inputs = input_layer, outputs = avg)\n    \n    #Extract feature.\n    feature_maps = feature_extractor.predict(data, verbose=1)\n    print('Feature maps shape: ', feature_maps.shape)\n    return feature_maps","metadata":{"execution":{"iopub.status.busy":"2023-06-13T11:58:34.943955Z","iopub.execute_input":"2023-06-13T11:58:34.944386Z","iopub.status.idle":"2023-06-13T11:58:34.953668Z","shell.execute_reply.started":"2023-06-13T11:58:34.944351Z","shell.execute_reply":"2023-06-13T11:58:34.952225Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"img_size = (331,331,3)\n# Extract features using InceptionV3 \nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\ninception_preprocessor = preprocess_input\ninception_features = get_features(InceptionV3,\n                                  inception_preprocessor,\n                                  img_size, images)\n\nprint('Inception feature maps shape', inception_features.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T12:00:12.529744Z","iopub.execute_input":"2023-06-13T12:00:12.530675Z","iopub.status.idle":"2023-06-13T12:00:22.778851Z","shell.execute_reply.started":"2023-06-13T12:00:12.530638Z","shell.execute_reply":"2023-06-13T12:00:22.777831Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 5s 5s/step\nFeature maps shape:  (1, 2048)\nInception feature maps shape (1, 2048)\n","output_type":"stream"}]},{"cell_type":"code","source":"np.argmax(model.predict(inception_features),axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T12:00:50.313779Z","iopub.execute_input":"2023-06-13T12:00:50.314750Z","iopub.status.idle":"2023-06-13T12:00:50.384612Z","shell.execute_reply.started":"2023-06-13T12:00:50.314713Z","shell.execute_reply":"2023-06-13T12:00:50.383734Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 19ms/step\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"array([49])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef images_to_array(directory, label_dataframe, target_size = input_shape):\n    \n    image_labels = label_dataframe['breed']\n    images = np.zeros([len(label_dataframe), target_size[0], target_size[1], target_size[2]],dtype=np.uint8) #as we have huge data and limited ram memory. uint8 takes less memory\n    y = np.zeros([len(label_dataframe),1],dtype = np.uint8)\n    \n    for ix, image_name in enumerate(tqdm(label_dataframe['id'].values)):\n        img_dir = os.path.join(directory, image_name + '.jpg')\n        img = load_img(img_dir, target_size = target_size)\n        images[ix] = img\n        del img\n        \n        dog_breed = image_labels[ix]\n        y[ix] = class_to_num[dog_breed]\n    \n    y = to_categorical(y)\n    \n    return images, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Make predictions\npredictions = model.predict(input_img)\n\n# Get the predicted dog breed\npredicted_breed = class_names[np.argmax(predictions)]\n\nprint(\"Predicted breed:\", predicted_breed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.load_model('/kaggle/working/model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-13T11:57:12.525476Z","iopub.execute_input":"2023-06-13T11:57:12.525841Z","iopub.status.idle":"2023-06-13T11:57:18.490323Z","shell.execute_reply.started":"2023-06-13T11:57:12.525812Z","shell.execute_reply":"2023-06-13T11:57:18.489099Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model.predict(images)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T11:57:21.703681Z","iopub.execute_input":"2023-06-13T11:57:21.704200Z","iopub.status.idle":"2023-06-13T11:57:22.222225Z","shell.execute_reply.started":"2023-06-13T11:57:21.704162Z","shell.execute_reply":"2023-06-13T11:57:22.212842Z"},"trusted":true},"execution_count":28,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/tmp/__autograph_generated_fileeja9rb77.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 2048), found shape=(None, 331, 331, 3)\n"],"ename":"ValueError","evalue":"in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 2048), found shape=(None, 331, 331, 3)\n","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}